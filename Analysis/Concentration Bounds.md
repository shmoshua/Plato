
> [!lemma] Theorem (Maximum of Squares)
> Let $x \sim \mathcal{N}(0,\Sigma)$ with $\Sigma_{jj}\leq 1$ for all $j\in[d]$. Then, $$\mathbb{E}\left[ \max_{j\in[d]} x^{2}_{j}\right]\leq O(\log d) $$

> [!proof]-
> We assume that we have a non-degenerate Gaussian distribution, i.e. $\Sigma_{ii}>0$ for all $i\in[d]$. Let $z:=\max_{i\in[d]} x_{i}^{2}$. For any $t>0$, $x\mapsto \exp(tx)$ is convex on $\mathbb{R}$, hence by Jensen and the tailsum formula,$$\exp(t\mathbb{E}[z])\leq \mathbb{E}[\exp(tz)]=\int_{0}^{\infty} \mathbb{P}(\exp (tz)\geq \lambda) \, d\lambda $$where: $$\begin{align}\mathbb{P}(\exp(tz)\geq \lambda)=\mathbb{P}(\max_{i\in[d]}\exp(tx_{i}^{2})\geq \lambda)=\mathbb{P}(\exists i\in[d]: \exp(tx^2_{i})\geq \lambda)\leq \sum_{i\in[d]}\mathbb{P}(\exp(tx^2_{i})\geq \lambda)\end{align}$$by union bound. Then, for any $i\in[d]$,  we have that $y_{i}:=\frac{1}{\sqrt{ \Sigma_{ii} }}x_{i}\sim \mathcal{N}(0,1)$ and:$$\begin{align}\mathbb{P}(\exp(tx^2_{i})\geq \lambda)=\mathbb{P}\left( \left| x_{i} \right| \geq \sqrt{ \frac{\log \lambda}{t} } \right)=\mathbb{P}\left( \left| y_{i} \right| \geq \sqrt{ \frac{\log \lambda}{\Sigma_{ii}t} } \right)\leq 2e^{-\frac{\log \lambda}{2\Sigma_{ii}t}}\leq 2e^{-\frac{\log \lambda}{2t}}=2\lambda^{-1/2t}\end{align}$$Hence, by taking $t=1/4$, $$\exp(\mathbb{E}[z] / 4)=\int_{0}^{\infty} \mathbb{P}(\exp (tz)\geq \lambda) \, d\lambda \leq \int_{0}^{1} 1 \, d\lambda+2d\int_{1}^{\infty} \lambda^{-2} \, d\lambda=1+2d $$This shows that $\mathbb{E}[z]\leq 4\log(2d+1)=O(\log d)$.