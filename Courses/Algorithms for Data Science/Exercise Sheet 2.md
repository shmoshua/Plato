#Algorithms #Series 

#### 1. Maximum of Squared Components of a Gaussian Vector
1. We assume that we have a non-degenerate Gaussian distribution, i.e. $\Sigma_{ii}>0$ for all $i\in[d]$. Let $z:=\max_{i\in[d]} x_{i}^{2}$. Then, by Jensen for any $t>0$,$$\exp(t\mathbb{E}[z])\leq \mathbb{E}[\exp(tz)]=\int_{0}^{\infty} \mathbb{P}(\exp (tz)\geq \lambda) \, d\lambda $$where: $$\begin{align}\mathbb{P}(\exp(tz)\geq \lambda)=\mathbb{P}(\max_{i\in[d]}\exp(tx_{i}^{2})\geq \lambda)=\mathbb{P}(\exists i\in[d]: \exp(tx^2_{i})\geq \lambda)\leq \sum_{i\in[d]}\mathbb{P}(\exp(tx^2_{i})\geq \lambda)\end{align}$$by union bound. Then, for any $i\in[d]$,  we have that $y_{i}:=\frac{1}{\sqrt{ \Sigma_{ii} }}x_{i}\sim \mathcal{N}(0,1)$ and:$$\begin{align}\mathbb{P}(\exp(tx^2_{i})\geq \lambda)=\mathbb{P}\left( \left| x_{i} \right| \geq \sqrt{ \frac{\log \lambda}{t} } \right)=\mathbb{P}\left( \left| y_{i} \right| \geq \sqrt{ \frac{\log \lambda}{\Sigma_{ii}t} } \right)\leq 2e^{-\frac{\log \lambda}{2\Sigma_{ii}t}}\leq 2e^{-\frac{\log \lambda}{2t}}=2\lambda^{-1/2t}\end{align}$$Hence, by taking $t=1/4$, $$\exp(\mathbb{E}[z] / 4)=\int_{0}^{\infty} \mathbb{P}(\exp (tz)\geq \lambda) \, d\lambda \leq 1+2d\int_{1}^{\infty} \lambda^{-2} \, d\lambda=1+2d $$This shows that $\mathbb{E}[z]\leq 4\log(2d+1)=O(\log d)$.
2. As $x\mapsto x^{2}$ is convex, by Jensen:$$\left( \mathbb{E}\left[ \frac{1}{\sqrt{ n }}\max_{i\in[d]}\left| \braket{ X_{i} , w }  \right|  \right]  \right)^{2}\leq \mathbb{E}\left[ \frac{1}{n}\max_{i\in[d]}\braket{ X_{i} , w }   ^{2} \right]=\mathbb{E}\left[ \max_{i\in[d]}\left\langle \frac{1}{\sqrt{ n }}X_{i},w\right\rangle^{2} \right]$$Now, notice that $\braket{ \frac{1}{\sqrt{ n }}X_{i} ,  w}$ is Gaussian as it is a sum of independent Gaussian variables. Further, $$\mathbb{E}\left[ \left\langle \frac{1}{\sqrt{ n }}X_{i},w\right\rangle\right] =\frac{1}{\sqrt{ n }}X_{i}^\top \mathbb{E}[w]=0,\quad\text{Var}\left( \frac{1}{\sqrt{ n }}X_{i}^\top w \right)=\frac{1}{n}X_{i}^\top X_{i}=\frac{1}{n}\left\| X_{i} \right\| ^2_{2}=1$$Hence, by 1, we get that: $\left( \mathbb{E}\left[ \frac{1}{\sqrt{ n }}\max_{i\in[d]}\left| \braket{ X_{i} , w }  \right|  \right]  \right)^{2}\leq O(\log d)$. Finally, $$\mathbb{E}\left[\max_{i\in[d]}\left| \braket{ X_{i} , w }  \right|  \right]  \leq \sqrt{ n }\cdot O(\log d)^{1/2}$$

---
#### 2. Ridge Regression

