#### Problem 1
1. Let $M\in \mathbb{R}^{n,n}$. Let $u_{1},\dots,u_{n},v_{1},\dots,v_{n}\in \mathbb{R}^{2n}$ be unit vectors. Then, we define $U:=(u_{1},\dots,u_{n})\in \mathbb{R}^{2n,n}$ and $V:=(v_{1},\dots,v_{n})\in \mathbb{R}^{2n,n}$. We define: $$X:=(U,V)\in \mathbb{R}^{2n,2n},\quad Z:=X^\top X\in \mathbb{R}^{2n,2n}$$Then, $Z$ is symmetric positive semidefinite as all matrices of this form are. Further, $$Z_{ii}=\sum_{j\in [2n]}^{}X_{ji}^2=1,\quad \forall i\in[2n]$$as $X$ only has unit columns. Now, notice that: $$\left\langle Z , \begin{bmatrix}0&M\\0&0\end{bmatrix} \right\rangle =\sum_{i,j\in[n]}^{}M_{ij} Z_{i,n+j}=\sum_{i,j\in[n]}^{}M_{ij} \sum_{k\in[2n]}^{}u_{i}(k)v_{j}(k)=\sum_{i,j\in[n]}^{}M_{ij} \braket{ u_{i} , v_{j} } $$Therefore, $f_{=}(M)\leq \left\| M \right\|_{G}$.
2. Let $M\in \mathbb{R}^{n,n}$. Let $X\in \mathbb{R}^{2n,2n}$ be a symmetric positive semidefinite matrix s.t. $\text{diag}(X)=I_{2n}$. Then, there exists a Cholesky decomposition s.t. $X=L^\top L$ with $L\in \mathbb{R}^{2n,2n}$. Let $(u_{1},\dots,u_{n},v_{1},\dots,v_{n}):= L$. We have that for any $i\in[n]$, $$1=(L^\top L)_{ii}=\left\| u_{i} \right\| ^{2}$$and similarly $\left\| v_{i} \right\|=1$. Now, we have: $$\left\langle X,\begin{bmatrix}0&M\\0&0\end{bmatrix}\right\rangle =\braket{ X_{1,2} , M } =\sum_{i,j\in[n]}^{}M_{ij}\braket{ u_{i} , v_{j} } $$and $\left\| M \right\|_{G}\leq f_{=}(M)$.
3. Let $M\in \mathbb{R}^{n,n}$. By definition we have that $f_{=}(M)\leq f_{\leq }(M)$. Conversely, let $u_{1},\dots,u_{n},v_{1},\dots,v_{n}\in \mathbb{R}^{2n}$ s.t. $\left\| u_{i} \right\|,\left\| v_{j} \right\|\leq 1$. 
   
   If none of the $u_{i},v_{j}=0$ then define $u'_{i}:= u_{i} / \left\| u_{i} \right\|$ and $v'_{j}:= v_{j} / \left\| v_{j} \right\|$. We then have: $$\sum_{i,j\in[n]}M_{ij}\braket{ u'_{i} , v'_{j} } =\sum_{i,j\in[n]} M_{ij}\braket{ u_{i} , v_{j} }\cdot  \frac{1}{\left\| u_{i} \right\| \left\| v_{j} \right\|} \geq\sum_{i,j\in[n]}M_{ij}\braket{ u_{i} , v_{j} }$$Now notice that for a fixed $k$, $$\sum_{i,j\in[n]}^{}M_{ij}\braket{ u_{i} , v_{j} } =\sum_{i\neq k}^{}\sum_{j\in[n]}^{}M_{ij}\braket{ u_{i} , v_{j} } +\sum_{j\in[n]}^{}M_{kj}\braket{ u_{k} , v_{j} } $$Then, we have $\sum_{j\in[n]}^{}M_{kj}\braket{ u_{k} , v_{j} }=u_{i}^\top\left(  \sum_{j\in[n]}^{}M_{kj}v_{j} \right)$. Therefore, if $u_{k}=0$, then there always exist a non-zero $u'_{k}$ with $\left\| u'_{k} \right\|\leq 1$ s.t. $\sum_{j\in[n]}^{}M_{kj}\braket{ u_{k}' , v_{j} }\geq 0$. This shows that we can reduce this case to the first, where none of the $u_{i},v_{j}=0$. 
   
   Therefore, this shows that $f_{=}(M)\geq f_{\leq }(M)$.

---
#### Problem 2
1. Notice that: $$\braket{ x^{>\tau} , Ay^{\leq \tau} } =\sum_{k,\ell\in[n]}^{}x^{> \tau}_{k}A_{k\ell} y^{\leq \tau}_{\ell}=\braket{ (w_{1}w_{1}^\top)_{1,2} , A }=\left\langle w_{1}w_{1}^\top , \begin{bmatrix}0&A\\0&0\end{bmatrix} \right\rangle  $$Hence, similarly, $$\braket{ x^{>\tau} , Ay^{\leq \tau} } +\braket{ x^{\leq\tau} , Ay^{> \tau} } +\braket{ x^{>\tau} , Ay^{> \tau} } =\left\langle w_{1}w_{1}^\top + w_{2}w_{2}^\top + w_{3}w_{3}^\top , \begin{bmatrix}0&A\\0&0\end{bmatrix} \right\rangle $$ Notice that: $$W_{ii}=\begin{cases}\mathbb{E}[2(x_{i}^{>\tau})^{2}+(x_{i}^{\leq\tau})^{2}]&1\leq i\leq n\\\mathbb{E}[2(y_{i}^{>\tau})^{2}+(y_{i}^{\leq\tau})^{2}]&n+1\leq i\leq 2n\end{cases}$$and as $x_{i},y_{i}$ they are all identically distributed, $\text{diag}(W)=W_{11}\cdot I_{2n}>0$. 
   
   Further, one sees that $W\succeq 0$ by definition as it is a sum of outer products and consequently $\frac{1}{W_{11}}W\succeq 0$. Therefore, we have that:$$\begin{aligned}\mathbb{E}[\braket{ x^{>\tau} , Ay^{\leq \tau} } +\braket{ x^{\leq\tau} , Ay^{> \tau} } +\braket{ x^{>\tau} , Ay^{> \tau} } ]=\left\langle W , \begin{bmatrix}0&A\\0&0\end{bmatrix} \right\rangle=W_{11}\left\langle \frac{1}{W_{11}} W , \begin{bmatrix}0&A\\0&0\end{bmatrix} \right\rangle\leq W_{11}\left\| A \right\| _{G}\end{aligned}$$

2. We claim that a sufficient condition is $\alpha\beta=1$. Similarly to above, we have that: $$W'_{ii}=\begin{cases}\mathbb{E}[(1+\alpha^{2})(x_{i}^{>\tau})^{2}+\beta^{2}(x_{i}^{\leq\tau})^{2}]&1\leq i\leq n\\\mathbb{E}[(1+\alpha^{2})(y_{i}^{>\tau})^{2}+\beta^{2}(y_{i}^{\leq\tau})^{2}]&n+1\leq i\leq 2n\end{cases}$$and as $x_{i},y_{i}$ they are all identically distributed, $\text{diag}(W')=W'_{11}\cdot I_{2n}>0$. Therefore, following an analogous argument we get that: $$\mathbb{E}[\braket{ \alpha x^{>\tau} , \beta Ay^{\leq \tau} } +\braket{ \beta x^{\leq\tau} , \alpha Ay^{> \tau} } +\braket{ x^{>\tau} , Ay^{> \tau} } ]\leq W'_{11}\|A\|_{G}$$We conclude the proof by noticing that as $\alpha\beta=1$, $$\mathbb{E}[\braket{ x^{>\tau} , Ay^{\leq \tau} } +\braket{ x^{\leq\tau} ,  Ay^{> \tau} } +\braket{ x^{>\tau} , Ay^{> \tau} } ]=\mathbb{E}[\braket{ \alpha x^{>\tau} , \beta Ay^{\leq \tau} } +\braket{ \beta x^{\leq\tau} , \alpha Ay^{> \tau} } +\braket{ x^{>\tau} , Ay^{> \tau} } ]$$

---